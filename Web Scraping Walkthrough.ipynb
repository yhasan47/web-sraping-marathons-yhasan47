{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Repository Information via Web-Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Do the imports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assess the problem\n",
    "\n",
    "We are currently in the `NSS-Data-Analytics-Cohort-2` cohort. \n",
    "In GitHub, the repositories for this cohort can be found at https://github.com/NSS-Data-Analytics-Cohort-2.\n",
    "\n",
    "## The Goal\n",
    "1. Access every repository URL associated with the `NSS-Data-Analytics-Cohort-2` organization.\n",
    "2. For every repository..\n",
    "    * Number of Commits (for the master branch)\n",
    "    * Number of branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Goal 1\n",
    "Accessing the repository urls. \n",
    "In order to do this.. \n",
    "We will need to go through every repository page and grab the repositories.\n",
    "\n",
    "The first question is.. \n",
    "How many pages should we traverse?\n",
    "In order to answer this, we need to locate the pagination element on the main page, and see how many options there are to select. \n",
    "Specifically, we need to figure out what the last number is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the base URLs for the project\n",
    "GITHUB_URL = 'https://github.com'\n",
    "ORG_URL = f'{GITHUB_URL}/NSS-Data-Analytics-Cohort-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data from the page\n",
    "resp = requests.get(ORG_URL)\n",
    "\n",
    "# We want the print statement to be 200\n",
    "print(resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the \"soup\" object so we can traverse the website content\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 1.A\n",
    "Figure out what the last page is!\n",
    "To do this, we need to access the pagination elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've created the soup.. Let's find the pagination elements.\n",
    "# Check the repositories page to find out what to look for!\n",
    "len(soup.findAll('div', {'class': 'pagination'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since `soup.findAll` returns a list of elements.. We need to extract the first result.\n",
    "pagination_elems = soup.findAll('div', {'class': 'pagination'})\n",
    "pagination_elem = pagination_elems[0]\n",
    "\n",
    "print(pagination_elem.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's get all of the links from the pagination element.\n",
    "links = pagination_elem.findAll('a')\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our case.. We are interested in the link that represents the final page. \n",
    "# So, 2 from the back.\n",
    "final_page = links[-2]\n",
    "final_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can get the text, and convert to an integer.\n",
    "final_page_number = int(final_page.text)\n",
    "final_page_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 1.B\n",
    "Now that we have the reference to the last page, we can use it to grab the links for all the pages.\n",
    "Speaking of which.. \n",
    "Notice the structure of the links from the pagination.\n",
    "\n",
    "Example: \n",
    "```\n",
    "/NSS-Data-Analytics-Cohort-2?page=3\n",
    "```\n",
    "\n",
    "It looks like if we want to be able to go through all the pages.. \n",
    "We would need to structure our links like the ones from the pagination links.\n",
    "\n",
    "So, our links should look like: \n",
    "```\n",
    "https://github.com/NSS-Data-Analytics-Cohort-2?page=1\n",
    "https://github.com/NSS-Data-Analytics-Cohort-2?page=2\n",
    "...\n",
    "https://github.com/NSS-Data-Analytics-Cohort-2?page=10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to build our structures!\n",
    "repo_pages = [f'{ORG_URL}?page={i+1}' for i in range(final_page_number)]\n",
    "repo_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 1.C\n",
    "\n",
    "Perfect. \n",
    "Next, we need to figure out a pattern to grab all of the repository links..\n",
    "\n",
    "Looking at the main page (`https://github.com/NSS-Data-Analytics-Cohort-2`) we can see that all of the repository elements are included in a `div` element with the `id` equal to `org-repositories`. \n",
    "Within that `div`, there is an unordered list (`ul`) with separate list elements (`li`) containing our info. \n",
    "\n",
    "Let's try to access those for the first pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_repositories = soup.find(id='org-repositories') \\\n",
    "    .find('ul') \\\n",
    "    .findAll('li')\n",
    "\n",
    "\n",
    "print(f'Total repositories on page: {len(org_repositories)}')\n",
    "print(org_repositories[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweet. Now, let's grab the link for the first one.\n",
    "# If we can grab that one.. We can grab the rest.\n",
    "first_repo = org_repositories[0]\n",
    "first_repo_a_elem = first_repo.find('a')\n",
    "print(first_repo_a_elem.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now.. The link!\n",
    "first_repo_a_elem.get('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 1.D\n",
    "\n",
    "Ok. \n",
    "Now.. \n",
    "We have the ability to get all the links!\n",
    "We just need to stitch all of our code together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_soup(url):\n",
    "    print(f'Fetching website data for: {url}')\n",
    "    resp = requests.get(url)\n",
    "    return BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "\n",
    "def get_org_repositories(soup):\n",
    "    print('\\tGetting org repositories')\n",
    "    return soup.find(id='org-repositories') \\\n",
    "        .find('ul') \\\n",
    "        .findAll('li')\n",
    "\n",
    "\n",
    "def extract_org_repository_links(org_repositories):\n",
    "    print('\\tGetting links from repositories')\n",
    "    return [repo.find('a').get('href') for repo in org_repositories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = []\n",
    "\n",
    "for url in repo_pages:\n",
    "    soup = get_page_soup(url)\n",
    "    org_repositories = get_org_repositories(soup)\n",
    "    links = extract_org_repository_links(org_repositories)\n",
    "    \n",
    "    all_links.extend(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert mic-drop here\n",
    "all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of links: {len(all_links)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 2.A\n",
    "\n",
    "Next, we need to pull some information per repository.\n",
    "\n",
    "> For every repository..\n",
    "* Number of Commits (for the master branch)\n",
    "* Number of branches\n",
    "\n",
    "Like before, let's start with a single repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_link = all_links[0]\n",
    "repo_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like before!\n",
    "resp = requests.get(f'{GITHUB_URL}{repo_link}')\n",
    "print(f'Status code is: {resp.status_code}')\n",
    "\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 2.B\n",
    "\n",
    "Now that we have the soup.. \n",
    "Let's focus on locating the appropriate elements. \n",
    "\n",
    "Looking at the website we notice that the elements of interest are inside list elements (`li`) within an unordered list (`ul`) having the class `numbers-summary`.\n",
    "Within those list elements are `span` elements with a `class` equal to `num`. \n",
    "Those are what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numbers_summary = soup.find('ul', {'class': 'numbers-summary'})\n",
    "print(numbers_summary.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for li in numbers_summary.findAll('li'):\n",
    "    \n",
    "    # grabbing the text, and doing a little cleanup\n",
    "    metric = li.find('span', {'class': 'num'}).text \\\n",
    "        .replace('\\n', '') \\\n",
    "        .strip()\n",
    "    \n",
    "    # going ahead and casting it to an integer if something was found!\n",
    "    if metric:\n",
    "        metric = int(metric)\n",
    "    else:\n",
    "        metric = None\n",
    "    \n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits, branches, *_ = metrics\n",
    "commits, branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 2.C\n",
    "\n",
    "Now, we put it all together! \n",
    "Just like before. \n",
    "This time, let's keep track of the repo link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers_summary(soup):\n",
    "    return soup.find('ul', {'class': 'numbers-summary'})\n",
    "\n",
    "\n",
    "def clean_metric(metric):\n",
    "    metric = metric \\\n",
    "        .replace('\\n', '') \\\n",
    "        .strip()\n",
    "    \n",
    "    if metric:\n",
    "        metric = int(metric)\n",
    "    else:\n",
    "        metric = None\n",
    "\n",
    "    return metric\n",
    "\n",
    "\n",
    "def get_metrics(numbers_summary):\n",
    "    metrics = []\n",
    "\n",
    "    for li in numbers_summary.findAll('li'):\n",
    "\n",
    "        # grabbing the text, and doing a little cleanup\n",
    "        metric = li.find('span', {'class': 'num'}).text\n",
    "        metrics.append(clean_metric(metric))\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure our functions work!\n",
    "numbers_summary = get_numbers_summary(soup)\n",
    "commits, branches, *_ = get_metrics(numbers_summary)\n",
    "commits, branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just look at our recent project.. HCBB\n",
    "\n",
    "hcbb_links = [l for l in all_links if 'healthcare-bluebook' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok.. Functions work for one.. \n",
    "# Time to try a few of them!!\n",
    "results = []\n",
    "\n",
    "for repo_ref in hcbb_links:\n",
    "    \n",
    "    url = f'{GITHUB_URL}{repo_ref}'\n",
    "    soup = get_page_soup(url)\n",
    "    \n",
    "    numbers_summary = get_numbers_summary(soup)\n",
    "    commits, branches, *_, contributors = get_metrics(numbers_summary)\n",
    "    commits, branches, contributors\n",
    "    \n",
    "    results.append((repo_ref, commits, branches, contributors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Goal 3!!!\n",
    "\n",
    "Now, of course, pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results, columns=['url', 'commits', 'branches', 'contributors'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is for you to explore on your own time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
